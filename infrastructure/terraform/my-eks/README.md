# Documenta√ß√£o T√©cnica - Cluster EKS Completo

## üìã Vis√£o Geral

Este projeto provisiona um **cluster Amazon EKS (Elastic Kubernetes Service) COMPLETO** na AWS usando Terraform, implementando uma arquitetura de alta disponibilidade com Control Plane e Worker Nodes distribu√≠dos em subnets privadas em m√∫ltiplas zonas de disponibilidade.

## üèóÔ∏è Arquitetura

### Diagrama de Rede
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                          VPC (10.0.0.0/16)                                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  AZ us-east-1a                    ‚îÇ  AZ us-east-1c                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ      ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ   ‚îÇ
‚îÇ Public Subnet (10.0.0.0/20)        ‚îÇ Public Subnet (10.0.16.0/20)           ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ ‚îÇ   üåê NAT Gateway        ‚îÇ         ‚îÇ ‚îÇ                          ‚îÇ           ‚îÇ
‚îÇ ‚îÇ   üì° Elastic IP         ‚îÇ         ‚îÇ ‚îÇ                          ‚îÇ           ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ Private Subnet (10.0.32.0/20)       ‚îÇ Private Subnet (10.0.48.0/20)          ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ ‚îÇ ‚öôÔ∏è  EKS Control Plane   ‚îÇ         ‚îÇ ‚îÇ ‚öôÔ∏è  EKS Control Plane    ‚îÇ           ‚îÇ
‚îÇ ‚îÇ üñ•Ô∏è  Worker Nodes (1-5)  ‚îÇ         ‚îÇ ‚îÇ üñ•Ô∏è  Worker Nodes (1-5)   ‚îÇ           ‚îÇ
‚îÇ ‚îÇ     t3.large instances  ‚îÇ         ‚îÇ ‚îÇ     t3.large instances   ‚îÇ           ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                        üåê Internet Gateway
```

## üîß Componentes da Infraestrutura

### 1. **üåê Rede (Network Module) - ‚úÖ ATIVO**
- **VPC**: `10.0.0.0/16` (65,536 IPs dispon√≠veis)
- **Subnets P√∫blicas**:
  - `us-east-1a`: `10.0.0.0/20` (4,094 IPs utiliz√°veis)
  - `us-east-1c`: `10.0.16.0/20` (4,094 IPs utiliz√°veis)
- **Subnets Privadas**:
  - `us-east-1a`: `10.0.32.0/20` (4,094 IPs utiliz√°veis)
  - `us-east-1c`: `10.0.48.0/20` (4,094 IPs utiliz√°veis)

### 2. **üö™ Gateway e Conectividade - ‚úÖ ATIVO**
- **Internet Gateway**: Para acesso √† internet das subnets p√∫blicas
- **NAT Gateway**: Localizado na subnet p√∫blica 1a para sa√≠da de internet das subnets privadas
- **Elastic IP**: `domain = "vpc"` (AWS Provider v5.100.0)
- **Route Tables**: Separadas para tr√°fego p√∫blico e privado

### 3. **‚öôÔ∏è Cluster EKS (Master Module) - ‚úÖ ATIVO**
- **Control Plane**: Executado nas subnets privadas (`us-east-1a` e `us-east-1c`)
- **Vers√£o Kubernetes**: `1.15` ‚ö†Ô∏è (DESATUALIZADA)
- **Security Group**: Permite tr√°fego HTTPS (443) de qualquer origem
- **IAM Roles**: 
  - `AmazonEKSClusterPolicy`
  - `AmazonEKSServicePolicy`

### 4. **üñ•Ô∏è Worker Nodes (Nodes Module) - ‚úÖ ATIVO**
- **Inst√¢ncias**: `t3.large`
- **Auto Scaling**:
  - M√≠nimo: 2 nodes
  - M√°ximo: 10 nodes  
  - Desejado: 2 nodes
- **Localiza√ß√£o**: Subnets privadas (ambas AZs)
- **IAM Policies**:
  - `AmazonEKS_CNI_Policy`
  - `AmazonEKSWorkerNodePolicy`
  - `AmazonEC2ContainerRegistryReadOnly`

## üìÅ Estrutura do Projeto

```
‚îú‚îÄ‚îÄ modules.tf              # ‚úÖ Todos os m√≥dulos definidos
‚îú‚îÄ‚îÄ provider.tf             # ‚úÖ AWS Provider v5.100.0
‚îú‚îÄ‚îÄ variables.tf            # ‚úÖ Todas as vari√°veis definidas
‚îú‚îÄ‚îÄ output.tf               # ‚ö†Ô∏è  Outputs (vazio)
‚îú‚îÄ‚îÄ .terraform.lock.hcl     # ‚úÖ Provider lockado
‚îú‚îÄ‚îÄ .gitignore              # ‚úÖ Git configurado
‚îî‚îÄ‚îÄ modules/
    ‚îú‚îÄ‚îÄ network/            # ‚úÖ M√≥dulo de rede (ATIVO)
    ‚îÇ   ‚îú‚îÄ‚îÄ vpc.tf          # VPC principal
    ‚îÇ   ‚îú‚îÄ‚îÄ public.tf       # Subnets p√∫blicas + associa√ß√µes
    ‚îÇ   ‚îú‚îÄ‚îÄ private.tf      # Subnets privadas + associa√ß√µes
    ‚îÇ   ‚îú‚îÄ‚îÄ internet.tf     # Internet Gateway e rotas p√∫blicas
    ‚îÇ   ‚îú‚îÄ‚îÄ nat-gateway.tf  # NAT Gateway, EIP e rotas privadas
    ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf    # Vari√°veis do m√≥dulo
    ‚îÇ   ‚îî‚îÄ‚îÄ output.tf       # ‚úÖ Outputs (VPC, subnets)
    ‚îú‚îÄ‚îÄ master/             # ‚úÖ M√≥dulo EKS Control Plane (ATIVO)
    ‚îÇ   ‚îú‚îÄ‚îÄ master.tf       # Cluster EKS
    ‚îÇ   ‚îú‚îÄ‚îÄ iam.tf          # Roles e pol√≠ticas IAM para cluster
    ‚îÇ   ‚îú‚îÄ‚îÄ security.tf     # Security Groups
    ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf    # Vari√°veis do m√≥dulo
    ‚îÇ   ‚îî‚îÄ‚îÄ output.tf       # ‚úÖ Outputs (cluster, security group)
    ‚îî‚îÄ‚îÄ nodes/              # ‚úÖ M√≥dulo Worker Nodes (ATIVO)
        ‚îú‚îÄ‚îÄ node_group.tf   # Node groups EKS
        ‚îú‚îÄ‚îÄ iam.tf          # Roles IAM para nodes
        ‚îî‚îÄ‚îÄ variables.tf    # Vari√°veis do m√≥dulo
```

## ‚öôÔ∏è Configura√ß√£o Atual

### Vari√°veis Principais

| Vari√°vel | Valor Configurado | Descri√ß√£o | Status |
|----------|-------------------|-----------|--------|
| `cluster_name` | `k8s-demo` | Nome do cluster EKS | ‚úÖ Ativo |
| `aws_region` | `us-east-1` | Regi√£o AWS | ‚úÖ Ativo |
| `k8s_version` | `1.15` | Vers√£o do Kubernetes | ‚ö†Ô∏è Desatualizada |
| `nodes_instances_sizes` | `["t3.large"]` | Tipos de inst√¢ncia para nodes | ‚úÖ Ativo |
| `auto_scale_options` | `{min=2, max=10, desired=2}` | Configura√ß√£o de auto scaling | ‚úÖ Ativo |

### Backend e Provider
- **Backend S3**: 
  - Bucket: `terragrunt-state-hugo-532582682531`
  - Key: `infra.tfstate`
  - Regi√£o: `us-east-1` ‚úÖ
  - Encryption: Habilitada ‚úÖ
- **AWS Provider**: `5.100.0` (constraint `~> 5.0`) ‚úÖ
- **Terraform**: `>= 1.3` ‚úÖ

## üöÄ Como Usar

### Pr√©-requisitos
- Terraform >= 1.3 ‚úÖ
- AWS CLI configurado
- Credenciais AWS com permiss√µes para EKS, EC2, VPC, IAM

### Deploy Completo (Control Plane + Worker Nodes)

```bash
# 1. Inicializar o Terraform
terraform init

# 2. Validar configura√ß√£o
terraform validate

# 3. Planejar deployment
terraform plan

# 4. Aplicar infraestrutura COMPLETA
terraform apply
```

### Conectar ao Cluster ap√≥s Deploy

```bash
# 1. Configurar kubectl
aws eks update-kubeconfig --region us-east-1 --name k8s-demo

# 2. Verificar nodes
kubectl get nodes

# 3. Verificar status do cluster
kubectl cluster-info
```

## üîí Seguran√ßa

### Caracter√≠sticas de Seguran√ßa Implementadas:
- ‚úÖ Control Plane em subnets privadas
- ‚úÖ Worker Nodes em subnets privadas
- ‚úÖ NAT Gateway para sa√≠da segura de internet
- ‚úÖ Security Groups configurados
- ‚úÖ IAM Roles com least privilege
- ‚úÖ State file criptografado no S3
- ‚úÖ Tr√°fego HTTPS (443) permitido para API do Kubernetes
- ‚úÖ Auto Scaling configurado com limites

### Defini√ß√£o de Subnets P√∫blicas vs Privadas:

#### **Subnets P√∫blicas** (`public.tf`):
```hcl
# Caracter√≠sticas que tornam a subnet p√∫blica:
map_public_ip_on_launch = true              # IPs p√∫blicos autom√°ticos
aws_route_table_association ‚Üí igw_route_table  # Associa√ß√£o com tabela do IGW

# Rota no Internet Gateway (internet.tf):
destination_cidr_block = "0.0.0.0/0"      # Todo tr√°fego
gateway_id = aws_internet_gateway.gw.id    # Via Internet Gateway
```

#### **Subnets Privadas** (`private.tf`):
```hcl
# Caracter√≠sticas que tornam a subnet privada:
# map_public_ip_on_launch = false (padr√£o)  # Sem IPs p√∫blicos autom√°ticos
aws_route_table_association ‚Üí nat          # Associa√ß√£o com tabela do NAT

# Rota no NAT Gateway (nat-gateway.tf):
destination_cidr_block = "0.0.0.0/0"      # Todo tr√°fego
nat_gateway_id = aws_nat_gateway.nat.id    # Via NAT Gateway
```

## üîß Status e Troubleshooting

### ‚úÖ Problemas Resolvidos

1. **‚úÖ "Missing region value"**
   - **RESOLVIDO**: Regi√£o adicionada no backend S3

2. **‚úÖ "vpc = true not expected"**
   - **RESOLVIDO**: Substitu√≠do por `domain = "vpc"`

3. **‚úÖ Worker Nodes n√£o aparecem**
   - **RESOLVIDO**: M√≥dulo `nodes` agora est√° ativo

### ‚ö†Ô∏è Melhorias Recomendadas

1. **üî¥ Vers√£o Kubernetes Cr√≠tica**
   ```
   Atual: 1.15 (End of Life - Sem suporte)
   Recomendado: 1.28+ (Suporte atual)
   ```

2. **üü° Outputs Ausentes**
   - Arquivo `output.tf` principal est√° vazio
   - N√£o √© poss√≠vel ver informa√ß√µes importantes ap√≥s deploy

## üìä Recursos Provisionados (Estado Atual)

### ‚úÖ Recursos Ativos
| Tipo | Quantidade | Localiza√ß√£o | Provider Version |
|------|------------|-------------|-------------------|
| VPC | 1 | us-east-1 | 5.100.0 |
| Subnets P√∫blicas | 2 | us-east-1a, us-east-1c | 5.100.0 |
| Subnets Privadas | 2 | us-east-1a, us-east-1c | 5.100.0 |
| Internet Gateway | 1 | VPC | 5.100.0 |
| NAT Gateway | 1 | us-east-1a | 5.100.0 |
| Elastic IP | 1 | us-east-1a | 5.100.0 |
| EKS Cluster | 1 | Subnets privadas | 5.100.0 |
| EKS Node Group | 1 | Subnets privadas | 5.100.0 |
| Worker Nodes | 2-10 | Auto Scaling | 5.100.0 |
| Route Tables | 2 | P√∫blica e Privada | 5.100.0 |
| Security Groups | 1 | Master SG | 5.100.0 |
| IAM Roles | 2 | Cluster + Nodes | 5.100.0 |

### Capacidade Total
- **IPs Dispon√≠veis**: 65.536 (VPC)
- **IPs por Subnet**: 4.094 utiliz√°veis
- **Worker Nodes**: 2 a 10 inst√¢ncias t3.large
- **Disponibilidade**: Multi-AZ (us-east-1a, us-east-1c)

## üè∑Ô∏è Tags Aplicadas

Todos os recursos s√£o taggeados com:
- `Name`: Formato `{cluster_name}-{tipo-recurso}`
- `kubernetes.io/cluster/{cluster_name}`: "shared" (cluster) / "owned" (nodes)

## ‚ö° A√ß√µes Recomendadas

### üî¥ Cr√≠ticas (Executar Imediatamente)
```bash
# 1. Atualizar vers√£o do Kubernetes
# Editar variables.tf:
variable "k8s_version" {
  default = "1.28"  # ou vers√£o mais recente
}

# 2. Aplicar atualiza√ß√£o
terraform plan
terraform apply
```

### üü° Melhorias (Pr√≥ximos Passos)
```bash
# 3. Adicionar outputs importantes
# No output.tf principal:
output "cluster_endpoint" {
  value = module.master.eks_cluster.endpoint
}

output "cluster_name" {
  value = var.cluster_name
}
```

### üü¢ Opcionais (Futuro)
1. **Add-ons EKS**: CoreDNS, kube-proxy, VPC CNI
2. **Monitoring**: CloudWatch Container Insights
3. **Load Balancers**: ALB Ingress Controller
4. **Storage**: EBS CSI Driver
5. **Security**: Pod Security Standards

## üéØ Status do Projeto

### ‚úÖ **COMPLETO E FUNCIONAL**
- ‚úÖ Rede configurada e segura
- ‚úÖ Control Plane ativo
- ‚úÖ Worker Nodes ativos
- ‚úÖ Auto Scaling configurado
- ‚úÖ Todas as depend√™ncias resolvidas
- ‚úÖ Provider atualizado (v5.100.0)

### ‚ö†Ô∏è **NECESSITA ATEN√á√ÉO**
- üî¥ Kubernetes 1.15 (CR√çTICO - Atualizar)
- üü° Outputs ausentes

O cluster est√° **FUNCIONAL** mas necessita atualiza√ß√£o da vers√£o do Kubernetes antes de uso em produ√ß√£o.

## ü§ù Contribui√ß√£o

Para modificar esta infraestrutura:
1. Fa√ßa altera√ß√µes nos arquivos .tf apropriados
2. Execute `terraform plan` para revisar mudan√ßas
3. Execute `terraform apply` para aplicar
4. Teste a funcionalidade
5. Atualize esta documenta√ß√£o

---
**√öltima an√°lise**: Junho 2025  
**Status**: ‚úÖ **CLUSTER COMPLETO E FUNCIONAL**  
**Prioridade**: üî¥ Atualizar Kubernetes 1.15 ‚Üí 1.28+  
**AWS Provider**: 5.100.0 ‚úÖ  
**Terraform**: >= 1.3 ‚úÖ


helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm repo update

helm install ingress-nginx ingress-nginx/ingress-nginx \
  --namespace ingress-nginx \
  --create-namespace \
  --set controller.service.type=LoadBalancer \
  --set controller.service.annotations."service\.beta\.kubernetes\.io/aws-load-balancer-type"="nlb"

## üåê Acessando a Aplica√ß√£o

### 1. Verificar Status do NLB

```bash
# Verificar o endpoint externo do NLB (pode levar alguns minutos para provisionar)
kubectl get svc -n ingress-nginx

# Aguardar at√© que EXTERNAL-IP n√£o seja <pending>
# O endpoint ser√° algo como: xxx-yyy.elb.us-region.amazonaws.com
```

### 2. Aplicar os Manifestos da Aplica√ß√£o

```bash
# Aplicar primeiro a aplica√ß√£o (cont√©m deployment, service, configmap)
kubectl apply -f kubernetes/apps/faker.yml

# Aplicar depois o ingress (depende do service)
kubectl apply -f kubernetes/apps/ingress.yml
```

### 3. Verificar Status dos Recursos

```bash
# Verificar pods
kubectl get pods

# Verificar services
kubectl get svc

# Verificar ingress (aguardar ADDRESS ser preenchido)
kubectl get ingress
```

### 4. Acessar a Aplica√ß√£o

Ap√≥s todos os recursos estarem rodando:

```bash
# Obter o endpoint do NLB
INGRESS_ENDPOINT=$(kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
echo "Acesse: http://$INGRESS_ENDPOINT"
```

**URLs da Aplica√ß√£o:**
- **Frontend**: `http://[NLB-ENDPOINT]/`
- **API**: `http://[NLB-ENDPOINT]/api/` (se configurado)
- **Admin**: `http://[NLB-ENDPOINT]/admin/` (se configurado)

### 5. Troubleshooting

```bash
# Se o NLB n√£o aparecer, verificar logs do controller
kubectl logs -n ingress-nginx deployment/ingress-nginx-controller

# Verificar eventos do ingress
kubectl describe ingress nginx-ingress-pathbased

# Testar conectividade interna
kubectl port-forward svc/frontend-service 8080:80
# Ent√£o acesse: http://localhost:8080
```

### 6. Limpeza (quando necess√°rio)

```bash
# Remover aplica√ß√£o
kubectl delete -f kubernetes/apps/

# Remover ingress controller
helm uninstall ingress-nginx -n ingress-nginx
kubectl delete namespace ingress-nginx
```